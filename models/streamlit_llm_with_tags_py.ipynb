{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file deploys the perfume recommender on Streamlit, including data with categorized reviews into sentiments, **tag generation**, Sentence-BERT model and LLM for perfume explanation."
      ],
      "metadata": {
        "id": "6XDLk72MC4y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Hmj5uyfkpO",
        "outputId": "a79b3077-e801-40ef-feb4-524ebd7d934f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "87UpmFTdNOXP",
        "outputId": "a1a5646f-7aa6-4aec-c533-d7a175f31313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.8.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.8.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2025.8.1)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.7.1)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.0.31.post1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.46.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.3.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.9.27)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.55.0)\n",
            "Requirement already satisfied: datasets<4.0.0,>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.9.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.16.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.22.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.18.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2025.3.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,>=4.51.3->unsloth) (0.21.2)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.1->unsloth) (25.1.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.1->unsloth) (0.19.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit unsloth sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To view Streamlit app in a browser later\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5moSLkLirkm",
        "outputId": "4a950080-7ed8-4f67-c012-bc501b6c2656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "import re\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "from transformers import TextStreamer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "st.title(\"Perfume Recommendation with Tag Generation\")\n",
        "st.write(\"üåÄ Starting app...\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_tag_model():\n",
        "    quantized_model_path = \"/content/drive/MyDrive/Colab Notebooks/totallymakescents/perfume_mistral_cpt_fine_tune_adapters-4bit\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    tag_model = AutoModelForCausalLM.from_pretrained(\n",
        "        quantized_model_path,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config\n",
        "    )\n",
        "    tag_tokenizer = AutoTokenizer.from_pretrained(quantized_model_path)\n",
        "\n",
        "    return tag_model, tag_tokenizer\n",
        "\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    save_path = \"/content/drive/MyDrive/Colab Notebooks/totallymakescents/llama-model/\"\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=save_path,\n",
        "        max_seq_length=2048,\n",
        "        dtype=None,\n",
        "        load_in_4bit=True,\n",
        "    )\n",
        "    tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "    FastLanguageModel.for_inference(model)\n",
        "    return model, tokenizer\n",
        "\n",
        "@st.cache_resource\n",
        "def load_sbert():\n",
        "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_embeddings():\n",
        "    return torch.load(\"/content/drive/MyDrive/Colab Notebooks/totallymakescents/perfume_embeddings.pt\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_dataframe():\n",
        "    return pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/totallymakescents/data/combined_df_classify_reviews.csv\")\n",
        "\n",
        "try:\n",
        "    st.write(\"üîß Loading LLM tag generation model...\")\n",
        "    tag_model, tag_tokenizer = load_tag_model()\n",
        "    st.success(\"‚úÖ Tag model loaded!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Error loading model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    st.write(\"üîß Loading LLM explanation model...\")\n",
        "    model, tokenizer = load_model()\n",
        "    st.success(\"‚úÖ Explanation model loaded!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Error loading model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    st.write(\"üìî Loading SBERT...\")\n",
        "    sbert_model = load_sbert()\n",
        "    st.success(\"‚úÖ SBERT loaded!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Error loading SBERT: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    st.write(\"üíê Loading perfume embeddings...\")\n",
        "    perfume_embeddings = load_embeddings()\n",
        "    st.success(\"‚úÖ Embeddings loaded!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Error loading embeddings: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    st.write(\"üìÑ Loading data...\")\n",
        "    combined_df_classify_reviews = load_dataframe()\n",
        "    st.success(\"‚úÖ Data loaded!\")\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ùå Error loading data: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "#generate tags\n",
        "def generate_tags(prompt, max_new_tokens=128):\n",
        "    tag_model.eval()\n",
        "    input_text = f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
        "    inputs = tag_tokenizer(input_text, return_tensors=\"pt\").to(tag_model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = tag_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7,\n",
        "            repetition_penalty=1.2,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    decoded = tag_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    cleaned = decoded.replace(\"<|im_start|>\", \"\").replace(\"<|im_end|>\", \"\").strip()\n",
        "    cleaned = re.sub(r\"\\b(nassistant\\n|assistant\\n|user\\n):?\", \"\", cleaned, flags=re.IGNORECASE)\n",
        "\n",
        "    if \"### Response:\" in cleaned:\n",
        "        cleaned = cleaned.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "#input format for LLM\n",
        "def format_for_explanation_with_tags(user_query, perfume_row, tags):\n",
        "    short_desc = (\n",
        "        f\"Top Notes: {perfume_row['Top']}. \"\n",
        "        f\"Middle Notes: {perfume_row['Middle']}. \"\n",
        "        f\"Base Notes: {perfume_row['Base']}. \"\n",
        "        f\"Main Accords: {', '.join([str(perfume_row.get(f'mainaccord{i}', '')) for i in range(1, 6)])}.\"\n",
        "    )\n",
        "    return {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            f\"User query: {user_query}\\n\"\n",
        "            f\"Perfume returned: {perfume_row['Perfume']} by {perfume_row['Brand']}\\n\"\n",
        "            f\"Notes: {short_desc}\\n\"\n",
        "            f\"Tags: {tags}\\n\"\n",
        "            f\"Please explain why this perfume fits the request, using both the tags and the notes.\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "#builds the app\n",
        "user_query = st.text_input(\"Describe your scent preference:\", placeholder=\"e.g. Looking for a bittersweet scent for a farewell party.\")\n",
        "top_k = st.slider(\"Number of Recommendations\", min_value=1, max_value=5, value=3)\n",
        "\n",
        "if st.button(\"Recommend and Explain\") and user_query:\n",
        "    with st.spinner(\"Finding matches and generating explanations...\"):\n",
        "      tags_text = generate_tags(user_query)\n",
        "\n",
        "      query_embedding = sbert_model.encode(tags_text, convert_to_tensor=True)\n",
        "      scent_tensor = perfume_embeddings.to(query_embedding.device)\n",
        "\n",
        "      similarities = util.cos_sim(query_embedding, scent_tensor)[0]\n",
        "\n",
        "      adjusted_scores = [] # boost scores of positive perfumes\n",
        "      for idx, score in enumerate(similarities):\n",
        "          sentiment_boost = 1.2 if combined_df_classify_reviews.loc[idx, 'is_positive'] == 1 else 0.8\n",
        "          adjusted_scores.append(score.item() * sentiment_boost)\n",
        "\n",
        "      adjusted_scores = torch.tensor(adjusted_scores)\n",
        "      top_results = torch.topk(similarities, k=top_k)\n",
        "\n",
        "      for score, idx in zip(top_results.values, top_results.indices):\n",
        "          idx = idx.item() # convert Python tensor to int\n",
        "          perfume = combined_df_classify_reviews.iloc[idx]\n",
        "          message = format_for_explanation_with_tags(user_query, perfume, tags_text)\n",
        "\n",
        "          inputs = tokenizer.apply_chat_template(\n",
        "              [message],\n",
        "              tokenize=True,\n",
        "              add_generation_prompt=True,\n",
        "              return_tensors=\"pt\",\n",
        "          ).to(\"cuda\")\n",
        "\n",
        "          text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "          with st.expander(f\"{perfume['Perfume']} by {perfume['Brand']} (Score: {score.item():.3f})\", expanded=True):\n",
        "              short_desc = (\n",
        "                  f\"Top Notes: {perfume['Top']}. \"\n",
        "                  f\"Middle Notes: {perfume['Middle']}. \"\n",
        "                  f\"Base Notes: {perfume['Base']}. \"\n",
        "                  f\"Main Accords: {', '.join([str(perfume.get(f'mainaccord{i}', '')) for i in range(1, 6)])}.\"\n",
        "              )\n",
        "\n",
        "              st.markdown(f\"**Notes**: {short_desc}\")\n",
        "\n",
        "              # LLM Explanation\n",
        "              output_llm = model.generate(\n",
        "                    input_ids=inputs,\n",
        "                    max_new_tokens=256,\n",
        "                    use_cache=True,\n",
        "                    temperature=1.5,\n",
        "                    min_p=0.1,\n",
        "                    streamer=text_streamer\n",
        "                )\n",
        "\n",
        "              full_output_llm = tokenizer.decode(output_llm[0], skip_special_tokens=True)\n",
        "\n",
        "              assistant_prefix = \"assistant\\n\"\n",
        "              if assistant_prefix in full_output_llm:\n",
        "                  llm_explanation = full_output_llm.split(assistant_prefix, 1)[-1].strip()\n",
        "              else:\n",
        "                  llm_explanation = full_output_llm.replace(message[\"content\"], \"\").strip()\n",
        "\n",
        "              st.markdown(\"**Explanation:**\")\n",
        "              st.markdown(llm_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFkPas9Tnwqi",
        "outputId": "4fc0a3b0-052b-4866-d41b-0fe44face79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import conf, ngrok\n",
        "ngrok.kill()  # reset tunnels\n",
        "\n",
        "ngrok_token = userdata.get('ngrok_KEY') # needs key from ngrok\n",
        "\n",
        "conf.get_default().auth_token = ngrok_token\n",
        "\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "print(\"Visit the app in the first link, not the local link:\\n\", public_url)\n",
        "\n",
        "!streamlit run streamlit_app.py --server.enableCORS false --server.enableXsrfProtection false --server.port 8501 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq1jp3iDn0Fr",
        "outputId": "ed2d46be-2e4c-466f-d3b5-71dce7c48cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the app in the first link, not the local link:\n",
            " NgrokTunnel: \"https://16dec494fc2c.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.71.201:8501\u001b[0m\n",
            "\u001b[0m\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "2025-08-06 18:57:45.260445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754506665.485764    7666 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754506665.549234    7666 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-06 18:57:46.090632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.55.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "model.safetensors: 100% 2.35G/2.35G [00:40<00:00, 57.5MB/s]\n",
            "generation_config.json: 100% 234/234 [00:00<00:00, 1.20MB/s]\n",
            "Unsloth 2025.8.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.82MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 647kB/s]\n",
            "README.md: 10.5kB [00:00, 28.5MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 394kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 1.78MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:01<00:00, 57.7MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.36MB/s]\n",
            "vocab.txt: 232kB [00:00, 10.5MB/s]\n",
            "tokenizer.json: 466kB [00:00, 34.1MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 736kB/s]\n",
            "config.json: 100% 190/190 [00:00<00:00, 1.52MB/s]\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Perfume Florasense by Jequiti fits the request for a fragrance that captures the essence of a natural new home because it includes the scent trek note. Scent trek is known to evoke feelings of happiness and is associated with fresh outdoor environments. Florasense also includes notes such as musk and cedar that will create the earthy scent of the new home. The scent is fresh, citrus, and powdery with a clean and woodsy theme. Overall, Florasense is an elegant and natural fragrance for capturing the essence of a new home.\n",
            "The perfume captures the essence of a natural new home because of the presence of citrus notes, musk and amber, and fresh notes such as green notes, osmanthus, and soursop, as well as sweet and powdery notes like tonka bean, vanilla, and sandlewood. The presence of woods, mosses, and citruses in the perfume also reflects the idea of a new home being surrounded by nature. The use of musk and amber provides a sensual touch, while the citruses and woods and mosses evoke a sense of freshness and cleanliness. Overall, this perfume fits the request by offering a clean, fresh scent with a sense of the natural world surrounding the home.\n",
            "This perfume would fit a natural new home request because it contains many of the scents associated with that idea - citrus, flowers, sandalwood and cedar - and is clean, musk, and amber. Additionally, the tags \"fairy like\" and \"fresh clean\" may indicate a light and airy scent that would be fitting for a natural new home.\n",
            "This perfume fits the request because it has notes of citrus and spices, a fresh, urban scent and is designed for a peaceful and calm environment. It has also been noted for a floral smell. The \"amber\" and \"yellow floral\" notes suggest that the perfume contains floralozone and citrus smells which fit the description of a peaceful alley. The wet plaster and industrial glue notes are more indicative of a calm space. It is clear that this perfume would be a good fit for this type of request.\n",
            "The perfume fits the request because it has notes such as bergamot, lavender and a top note with the words such a perfume would probably contain notes of citrus smells'.\n",
            "This perfume fits the request of a peaceful alley due to its inclusion of notes like lavender and grapefruit, which have a calming effect. Additionally, the notes of incense, iris, violet, and jasmine add an air of serenity and peacefulness. The base notes of amber, cedar, and resins further enhance the peaceful atmosphere, as they contribute to a sense of tranquility and calmness. Overall, the notes in this perfume evoke a sense of serenity, making it perfect for an alley.\n",
            "Halloween Blue Drop by Halloween fits the request for its scents of lavender, clean and urban notes, citrus smells, musk, spices, amber, and calypsone - all of which suggest a sense of freshness, cleanliness, and a hint of a city environment.\n",
            "This perfume fits the request for a peaceful alley scent as it features scents of orange blossom, lavender, bergamot and citrus. It also features a strong clean smell that fits in the background for the city sounds. It also has a smell similar to smoke, which may evoke the feeling of walking down an alley way at night. The musky accord with tonka bean is a classic combination used for a relaxing scent. The combination of violet, white musk and precious woods is also very relaxing. Overall, this perfume fits the request by featuring both a calming floral scent as well as a background of clean urban scents.\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}